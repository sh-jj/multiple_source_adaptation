{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import scipy \n",
    "import random\n",
    "from scipy.stats import multivariate_normal as mn\n",
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = 0.01\n",
    "nC = 1000 # number of points per class\n",
    "p  = 3 # number of domains\n",
    "C  = 10 # number of classes\n",
    "n  = nC*p*C\n",
    "U = 1.0/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_D_h(nC, p, C):\n",
    "    D = np.random.rand(nC*p*C,C,p) # prob point n is in domain p and class C\n",
    "    h = np.random.rand(nC*p*C,C,p) # score for point n in domain p and class C\n",
    "    # normalize D and h\n",
    "    for k in range(p): # loop over domain\n",
    "        D[:,:,k] = D[:,:,k] / D[:,:,k].sum()\n",
    "    \n",
    "        for i in range(nC):\n",
    "            h[i,:,k] = h[i,:,k]/h[i,:,k].sum() # since this is the output of a softmax function its normalized over classes \n",
    "    return D,h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a data problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class synthetic_problem():\n",
    "    \n",
    "    def __init__(self, p=3, nC=20, c=10, seed=1337):\n",
    "        self.p = p # number of domains\n",
    "        self.nC = nC # pts per class\n",
    "        self.C = C # number of classes\n",
    "        self.n = nC * p * C # num pts\n",
    "        self.U = 1.0 / self.n # unif dist\n",
    "        self.eta = 0.01\n",
    "        self.seed = seed\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        self.generate_density()\n",
    "        self.generate_regressor()\n",
    "        self.generate_y()\n",
    "        \n",
    "    def generate_density(self):\n",
    "        D = np.random.rand(self.n,self.p)\n",
    "        # Normalize each domain\n",
    "        for k in range(self.p):\n",
    "            D[:,k] = D[:,k] / D[:,k].sum()\n",
    "        self.D = D\n",
    "    \n",
    "    def generate_regressor(self):\n",
    "        h = np.random.rand(self.n,self.p)\n",
    "        for k in range(self.p):\n",
    "            h[:,k] = h[:,k] / h[:,k].sum()\n",
    "        self.h = h\n",
    "        \n",
    "        # compute H\n",
    "        self.H = np.zeros(self.n)\n",
    "        for i in range(self.n):\n",
    "            self.H[i] = 1.0 / self.p * h[i,:].sum()\n",
    "            \n",
    "    def generate_y(self):\n",
    "        y = np.random.rand(self.n)\n",
    "        y = y / y.sum()\n",
    "        self.y = y\n",
    "        \n",
    "    def get_marginal_density(self):\n",
    "        return self.D\n",
    "    \n",
    "    def get_regressor(self):\n",
    "        return self.h\n",
    "    \n",
    "    def get_true_values(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_H(self):\n",
    "        return self.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sentiment_analysis_data():\n",
    "    \n",
    "    def __init__(self, datadir=''):\n",
    "        self.datadir = datadir\n",
    "        self.domains = ('books', 'dvd', 'electronics', 'kitchen')\n",
    "        self.label_fmt = 'exp{split}/rawdata/{domain}.{dset}.labels'\n",
    "        self.data_fmt = 'exp{split}/rawdata/{domain}.{dset}.txt'\n",
    "        \n",
    "    def load_data(self, domain, split, dset='train'):\n",
    "        dname = self.data_fmt.format(split=split, \n",
    "                                        domain=domain, dset=dset)\n",
    "        with open(join(self.datadir, dname), 'rb') as f:\n",
    "            data = f.read().splitlines()\n",
    "        return data\n",
    "    \n",
    "    def load_labels(self, domain, split, dset='train'):\n",
    "        dname = self.label_fmt.format(split=split, domain=domain, dset=dset)\n",
    "        with open(join(self.datadir, dname), 'rb') as f:\n",
    "            data = f.read().splitlines()\n",
    "        labels = np.array([float(x) for x in data])\n",
    "        return labels\n",
    "    \n",
    "    def load_prob(self, tr_dom, dom, split, n, minO, dset, scale=50):\n",
    "        \"\"\"\n",
    "        Loads the precomputed probs of each example in dom\n",
    "        according to the model trained on tr_dom. Each is \n",
    "        computed over the particular data <split> using an\n",
    "        <n>-gram language model with vocabulary based on the\n",
    "        minimum occurances (minO) of each word across all domains\n",
    "        in sentiment analysis dataset.\n",
    "        \"\"\"\n",
    "        prob_fmt = 'exp{:d}/prob-{:d}gram-{:d}minoccur/{:s}.{:s}-in-{:s}.prob'\n",
    "        prob_file = prob_fmt.format(split, n, minO, dom, dset, tr_dom)\n",
    "        with open(join(self.datadir, prob_file), 'rb') as f:\n",
    "            data = f.read().splitlines()\n",
    "        #prob = np.array([np.exp(-float(x)/scale) for x in data])\n",
    "        prob = np.array([np.exp(-float(x)) for x in data])\n",
    "        nlogprob = np.array([float(x) for x in data])\n",
    "        return prob, nlogprob\n",
    "    \n",
    "    def load_pred(self, tr_dom, dom, split, dset):\n",
    "        pred_fmt = 'exp{:d}/predictions/{:s}.{:s}.libsvm-on-{:s}.train.libsvm.model.pred'\n",
    "        pred_file = pred_fmt.format(split, dom, dset, tr_dom)\n",
    "        with open(join(self.datadir, pred_file), 'rb') as f:\n",
    "            data = f.read().splitlines()\n",
    "        pred = np.array([float(x) for x in data])\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadir = '/data/sentiment_analysis/domain_adaptation/'\n",
    "SA = sentiment_analysis_data(datadir=datadir)\n",
    "split = 1\n",
    "sources = ['kitchen', 'dvd']\n",
    "\n",
    "p = len(sources)\n",
    "y = []\n",
    "#for s in sources:\n",
    "#    ys = \n",
    "y = []\n",
    "ys = SA.load_labels('dvd', 1)\n",
    "y.append(ys)\n",
    "ys2 = SA.load_labels('books',1)\n",
    "y.append(ys2)\n",
    "pred = SA.load_pred('books', 'dvd', 1, 'train')\n",
    "prob, lp = SA.load_prob('books', 'dvd', 1, 1, 2, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.58602720e-132   8.86069149e-213   3.33586796e-085 ...,\n",
      "   8.68431588e-039   5.82896668e-051   0.00000000e+000] [  303.48     488.269    194.515  ...,    87.6393   115.669   1136.72  ] (1600,) (1600,)\n",
      "[  1.58602720e-132   8.86069149e-213   3.33586796e-085 ...,\n",
      "   8.68431588e-039   5.82896668e-051   0.00000000e+000] 0.0 1.46540502801e-18\n",
      "[  1.19833893e-52   1.62872950e-41] [  1.19833893e-52   1.62872950e-41]\n"
     ]
    }
   ],
   "source": [
    "print prob, lp, prob.shape, pred.shape\n",
    "o = np.exp(-lp)\n",
    "print o, o.min(), o.max()\n",
    "\n",
    "DP = sm_problem(datadir=datadir, minO=2, ngram=1, \n",
    "                split=1, sources=('kitchen', 'dvd'))\n",
    "\n",
    "h = DP.get_regressor()\n",
    "D = DP.get_marginal_density()\n",
    "d = DP.get_nlog_density()\n",
    "\n",
    "z = 1.0/DP.p * np.ones(DP.p)\n",
    "\n",
    "def compute_Jz_reg(z, h, D, p):\n",
    "    zDh = 0\n",
    "    for k in range(p):\n",
    "        zDh += z[k] * D[k] * h[k]\n",
    "    return zDh\n",
    "\n",
    "def compute_Jz_log(z, h, d,p):\n",
    "    \"Assumes d=-log(D)\"\n",
    "    zDh = 0\n",
    "    for k in range(p):\n",
    "        zDh += np.exp(np.log(z[k]*h[k]) - d[k])\n",
    "    return zDh\n",
    "\n",
    "Jz_r = compute_Jz_reg(z, h, D, DP.p)\n",
    "Jz_l = compute_Jz_log(z, h, d, DP.p)\n",
    "\n",
    "print Jz_r, Jz_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "ys.shape, pred.shape, prob.shape\n",
    "print np.hstack(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sm_problem():\n",
    "    \n",
    "    def __init__(self, split=1, datadir='', sources=None,\n",
    "                ngram=1, minO=2):\n",
    "        self.datadir = datadir # directory where data is stored\n",
    "        self.split = split\n",
    "        self.ngram = ngram\n",
    "        self.minO = minO\n",
    "        self.splitdir = join(datadir, 'exp{:d}'.format(split))\n",
    "        self.sources = sources\n",
    "        self.p = len(sources) # number of domains\n",
    "        self.SA = sentiment_analysis_data(datadir=datadir)\n",
    "        \n",
    "        self.load_y() # load the gt labels and set self.n\n",
    "        self.load_density()\n",
    "        self.load_regressor()\n",
    "        self.U = 1.0 / self.n # unif dist\n",
    "        self.eta = 0.01\n",
    "        \n",
    "        \n",
    "    def load_density(self):\n",
    "        D = np.zeros([self.n,self.p])\n",
    "        logD = np.zeros([self.n, self.p])\n",
    "        for (k,d_tr) in enumerate(self.sources):\n",
    "            Dd = []; logD_d = [];\n",
    "            for d in self.sources:\n",
    "                prob_d, nlogp = self.SA.load_prob(d_tr, d, self.split, \n",
    "                             self.ngram, self.minO, 'train')\n",
    "                Dd.append(prob_d)\n",
    "                logD_d.append(nlogp)\n",
    "            D[:,k] = np.hstack(Dd)\n",
    "            logD[:,k] = np.hstack(logD_d)\n",
    "        self.D = D\n",
    "        self.logD = logD\n",
    "    \n",
    "    def load_regressor(self):\n",
    "        h = np.zeros([self.n,self.p])\n",
    "        for (k, d_tr) in enumerate(self.sources):\n",
    "            hd = []\n",
    "            for d in self.sources:\n",
    "                hd.append(self.SA.load_pred(d_tr, d, self.split,\n",
    "                                         'train'))\n",
    "            h[:,k] = np.hstack(hd)\n",
    "        self.h = h\n",
    "        \n",
    "        # compute H\n",
    "        self.H = np.zeros(self.n)\n",
    "        for i in range(self.n):\n",
    "            self.H[i] = 1.0 / self.p * h[i,:].sum()\n",
    "            \n",
    "    def load_y(self):\n",
    "        y = []\n",
    "        for s in self.sources:\n",
    "            y.append(self.SA.load_labels(s, self.split))\n",
    "        self.y = np.hstack(y)\n",
    "        self.n = self.y.shape[0]\n",
    "        \n",
    "    def get_marginal_density(self):\n",
    "        return self.D\n",
    "    \n",
    "    def get_nlog_density(self):\n",
    "        return self.logD\n",
    "    \n",
    "    def get_regressor(self):\n",
    "        return self.h\n",
    "    \n",
    "    def get_true_values(self):\n",
    "        return self.y\n",
    "    \n",
    "    def get_H(self):\n",
    "        return self.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DP = sm_problem(datadir=datadir, minO=2, ngram=1, \n",
    "                split=1, sources=('kitchen', 'dvd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* z_{t+1} = argmin gamma\n",
    "* subject to\n",
    "    * u_k(z) - v_k(z_t) - (z - z_t) grad_{v_k(z_t)} <= g for all k in [p]\n",
    "    * -z_k <= 0 forall k in [p]\n",
    "    * sum_{k=1}^p z_k - 1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_H(x, DP):\n",
    "    return DP.get_H()[x]\n",
    "\n",
    "def compute_Dz(x, z, DP):\n",
    "    \"\"\" Dz = sum_k z_k * D_k(x)\"\"\"\n",
    "    D = DP.get_marginal_density()[x,:]\n",
    "    Dz = 0\n",
    "    for k in range(DP.p):\n",
    "        Dz += z[k] * D[k]\n",
    "    return Dz\n",
    "\n",
    "def compute_Jz(x, z, DP):\n",
    "    const = DP.eta * DP.U * compute_H(x, DP)\n",
    "    D = DP.get_marginal_density()[x,:]\n",
    "    h = DP.get_regressor()[x,:]\n",
    "    zDh = 0\n",
    "    for k in range(DP.p):\n",
    "        zDh += z[k] * D[k] * h[k]\n",
    "    return zDh + const\n",
    "\n",
    "def compute_Kz(x, z, DP):\n",
    "    return compute_Dz(x, z, DP) + DP.eta * DP.U\n",
    "\n",
    "def compute_hz(x, z, DP, Jz=None, Kz=None):\n",
    "    if Jz is None:\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "    if Kz is None:\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "        \n",
    "    return Jz / Kz\n",
    "\n",
    "def compute_fz(x, z, DP, Jz=None, Kz=None):\n",
    "    if not Jz:\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "    if not Kz:\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "    return (Jz + 1) ** 2 / (2*Kz)\n",
    "\n",
    "def compute_gz(x, z, DP, Jz=None, Kz=None):\n",
    "    if not Jz:\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "    if not Kz:\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "    return ((Jz**2) + 1) / (2*Kz)\n",
    "\n",
    "def compute_Fz(x, z, DP, fz=None, gz=None):\n",
    "    if not fz:\n",
    "        fz = compute_fz(x, z, DP)\n",
    "    if not gz:\n",
    "        gz = compute_gz(x, z, DP)\n",
    "    return 2 * (fz**2) + 2 * (gz**2)\n",
    "\n",
    "def compute_Gz(x, z, DP, fz=None, gz=None):\n",
    "    if not fz:\n",
    "        fz = compute_fz(x, z, DP)\n",
    "    if not gz:\n",
    "        gz = compute_gz(x, z, DP)\n",
    "    return (fz + gz)**2\n",
    "\n",
    "def compute_grad_Jz(x, z, DP):\n",
    "    D = DP.get_marginal_density()\n",
    "    h = DP.get_regressor()\n",
    "    return D[x,:] * h[x,:]\n",
    "\n",
    "def compute_grad_Kz(x, z, DP):\n",
    "    D = DP.get_marginal_density()[x,:]\n",
    "    return D\n",
    "\n",
    "def compute_grad_gz(x, z, DP, grad_Jz=None, \n",
    "                    grad_Kz=None, Jz=None,\n",
    "                   Kz=None):\n",
    "    if grad_Jz is None:\n",
    "        grad_Jz = compute_grad_Jz(x, z, DP)\n",
    "    if grad_Kz is None:\n",
    "        grad_Kz = compute_grad_Kz(x, z, DP)\n",
    "    if not Jz:\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "    if not Kz:\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "    return (Jz * grad_Jz) / Kz - (((Jz**2) + 1)*grad_Kz) / Kz\n",
    "\n",
    "def compute_grad_fz(x, z, DP, Jz=None, Kz=None,\n",
    "                    grad_Jz=None, grad_Kz=None):\n",
    "    if grad_Jz is None:\n",
    "        grad_Jz = compute_grad_Jz(x, z, DP)\n",
    "    if grad_Kz is None:\n",
    "        grad_Kz = compute_grad_Kz(x, z, DP)\n",
    "    if not Jz:\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "    if not Kz:\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "    return (Jz + 1)*grad_Jz / Kz - (Jz+1)**2 * grad_Kz / (Kz**2)\n",
    "\n",
    "def compute_grad_Gz(x, z, DP, fz=None, gz=None,\n",
    "                   grad_fz=None, grad_gz=None):\n",
    "    if not fz:\n",
    "        fz = compute_fz(x, z, DP)\n",
    "    if not gz:\n",
    "        gz = compute_gz(x, z, DP)\n",
    "    if grad_fz is None:\n",
    "        grad_fz = compute_grad_fz(x, z, DP)\n",
    "    if grad_gz is None:\n",
    "        grad_gz = compute_grad_gz(x, z, DP)\n",
    "    return 2 * (fz + gz) * (grad_fz + grad_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define u and v following proposition 9\n",
    "def compute_u(z,DP):\n",
    "    D = DP.get_marginal_density()\n",
    "    h = DP.get_regressor()\n",
    "    etaU = DP.eta * DP.U\n",
    "    y = DP.get_true_values()\n",
    "    \n",
    "    const = np.zeros(DP.n)\n",
    "    for k in range(DP.p):\n",
    "        const += z[k] * D[:,k] * (y**2)\n",
    "\n",
    "    u = np.zeros(DP.p)\n",
    "    for x in range(DP.n):\n",
    "        H = compute_H(x, DP)\n",
    "        Dz = compute_Dz(x, z, DP)\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "        hz = compute_hz(x, z, DP, Jz=Jz, Kz=Kz)\n",
    "        fz = compute_fz(x, z, DP, Jz=Jz, Kz=Kz)\n",
    "        gz = compute_gz(x, z, DP, Jz=Jz, Kz=Kz)\n",
    "        Fz = compute_Fz(x, z, DP, fz=fz, gz=gz)\n",
    "        Gz = compute_Gz(x, z, DP, fz=fz, gz=gz)\n",
    "        \n",
    "        for k in range(DP.p):\n",
    "            Dk = D[x,k]\n",
    "            hk = h[x,k]\n",
    "\n",
    "            v1 = Dk * (Fz + 2*y[x]*gz + y[x]**2)\n",
    "            v2 = etaU*Fz + 2*y[x]*Jz + 2*etaU*y[x]*gz\n",
    "            u[k] += v1 + v2 \n",
    "    return u - const.sum()\n",
    "\n",
    "def compute_v(z, DP):\n",
    "    D = DP.get_marginal_density()\n",
    "    h = DP.get_regressor()\n",
    "    H = DP.get_H()\n",
    "    y = DP.get_true_values()\n",
    "\n",
    "    v = np.zeros(DP.p)\n",
    "    for x in range(DP.n):\n",
    "        Gz = compute_Gz(x, z, DP)\n",
    "        fz = compute_fz(x, z, DP)\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "        hz = compute_hz(x, z, DP, Jz=Jz)\n",
    "\n",
    "        etaU = DP.eta * DP.U\n",
    "        va = D[x,:] * (Gz + 2*fz*y[x])\n",
    "        vb = Jz * hz + etaU*Gz + 2*etaU*fz*y[x]\n",
    "        v += va + vb\n",
    "    return v\n",
    "\n",
    "def compute_grad_v(z, DP):\n",
    "    D = DP.get_marginal_density()\n",
    "    h = DP.get_regressor()\n",
    "    H = DP.get_H()\n",
    "    y = DP.get_true_values()\n",
    "    \n",
    "    grad_v = np.zeros([DP.p, DP.p])\n",
    "    for x in range(DP.n):\n",
    "        grad_Gz = compute_grad_Gz(x, z, DP)\n",
    "        grad_fz = compute_grad_fz(x, z, DP)\n",
    "        Jz = compute_Jz(x, z, DP)\n",
    "        Kz = compute_Kz(x, z, DP)\n",
    "        grad_Jz = D[x,:] * h[x,:]\n",
    "        grad_Kz = D[x,:]\n",
    "        etaU = DP.eta * DP.U\n",
    "        etaUH = etaU * H[x]\n",
    "        grad_Jzhz = 2*(Jz/Kz)*grad_Jz - ((Jz**2)/(Kz**2)) * grad_Kz \n",
    "        a0 = D[x,:] + etaU\n",
    "        a1 = 2 * y[x]*D[x,:] + 2 * etaUH * y[x]\n",
    "        for k in range(DP.p): #kth element of v\n",
    "            for i in range(DP.p): # ith grad dim\n",
    "                a0 = (D[x,k] + etaU) * grad_Gz[i]\n",
    "                a1 = (2*D[x,k]*y[x] + 2*etaU*y[x]) * grad_fz[i]\n",
    "                a2 = grad_Jzhz[i]\n",
    "                grad_v[k,i] += a0 + a1 + a2\n",
    "\n",
    "    return np.matrix(grad_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2, 2)\n",
      "[  1.02402911e+09   1.02402911e+09]\n",
      "[[ -6.90274782e+00  -7.09684052e-09]\n",
      " [ -6.90267944e+00  -7.09684052e-09]]\n"
     ]
    }
   ],
   "source": [
    "v = compute_v(zp, DP)\n",
    "gv = compute_grad_v(zp, DP)\n",
    "print v.shape, gv.shape\n",
    "print v\n",
    "print gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: [ 0.25  0.25  0.25  0.25] x: 0\n",
      "H(x) 1.69309\n",
      "Dz(x) 5.15529136316e-86\n",
      "Jz(x) 2.645453125e-06\n",
      "Kz(x) 1.5625e-06\n",
      "fz(x) 320001.693092\n",
      "gz(x) 320000.000002\n",
      "Fz(x) 409602167167.0\n",
      "Gz(x) 409602167164.0\n",
      "grad_Jz(x) [  1.04641566e-107   2.46880740e-116   1.96721813e-111   4.35356107e-085]\n",
      "grad_Kz(x) [  6.61400945e-108   1.29935864e-116   1.66853388e-111   2.06211655e-085]\n",
      "grad_gz(x) [ -4.23294833e-102  -8.31585348e-111  -1.06785835e-105  -1.31974722e-079]\n",
      "grad_fz(x) [ -2.70910591e-096  -5.32218534e-105  -6.83433833e-100  -8.44644620e-074]\n",
      "grad_Gz(x) [ -3.46767015e-90  -6.81242590e-99  -8.74798987e-94  -1.08114966e-67]\n"
     ]
    }
   ],
   "source": [
    "#DP = synthetic_problem()\n",
    "DP = sm_problem(datadir=datadir, minO=2, ngram=1, \n",
    "                split=1, sources=('kitchen', 'dvd', 'books', 'electronics'))\n",
    "zp = np.repeat(1.0 / DP.p, DP.p)\n",
    "x=0\n",
    "print 'z:', zp, 'x:', x\n",
    "print 'H(x)', compute_H(x, DP)\n",
    "print 'Dz(x)', compute_Dz(x, zp, DP)\n",
    "print 'Jz(x)', compute_Jz(x, zp, DP)\n",
    "print 'Kz(x)', compute_Kz(x, zp, DP)\n",
    "print 'fz(x)', compute_fz(x, zp, DP)\n",
    "print 'gz(x)', compute_gz(x, zp, DP)\n",
    "print 'Fz(x)', compute_Fz(x, zp, DP)\n",
    "print 'Gz(x)', compute_Gz(x, zp, DP)\n",
    "print 'grad_Jz(x)', compute_grad_Jz(x, zp, DP)\n",
    "print 'grad_Kz(x)', compute_grad_Kz(x, zp, DP)\n",
    "print 'grad_gz(x)', compute_grad_gz(x, zp, DP)\n",
    "print 'grad_fz(x)', compute_grad_fz(x, zp, DP)\n",
    "print 'grad_Gz(x)', compute_grad_Gz(x, zp, DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: [ 0.25  0.25  0.25  0.25] x: 0\n",
      "fz(x) 320001.693092\n",
      "gz(x) 320000.000002\n",
      "Fz(x) 409602167167.0\n",
      "Gz(x) 409602167164.0\n",
      "grad_Jz(x) [  1.04641566e-107   2.46880740e-116   1.96721813e-111   4.35356107e-085]\n",
      "grad_Kz(x) [  6.61400945e-108   1.29935864e-116   1.66853388e-111   2.06211655e-085]\n",
      "grad_gz(x) [ -4.23294833e-102  -8.31585348e-111  -1.06785835e-105  -1.31974722e-079]\n",
      "grad_fz(x) [ -2.70910591e-096  -5.32218534e-105  -6.83433833e-100  -8.44644620e-074]\n",
      "grad_Gz(x) [ -3.46767015e-90  -6.81242590e-99  -8.74798987e-94  -1.08114966e-67]\n"
     ]
    }
   ],
   "source": [
    "print 'z:', zp, 'x:', x\n",
    "H = compute_H(x, DP)\n",
    "Dz = compute_Dz(x, zp, DP)\n",
    "Jz = compute_Jz(x, zp, DP)\n",
    "Kz = compute_Kz(x, zp, DP)\n",
    "fz = compute_fz(x, zp, DP, Jz=Jz, Kz=Kz)\n",
    "gz = compute_gz(x, zp, DP, Jz=Jz, Kz=Kz)\n",
    "Fz = compute_Fz(x, zp, DP, fz=fz, gz=gz)\n",
    "Gz = compute_Gz(x, zp, DP, fz=fz, gz=gz)\n",
    "grad_Jz = compute_grad_Jz(x, zp, DP)\n",
    "grad_Kz = compute_grad_Kz(x, zp, DP)\n",
    "grad_gz = compute_grad_gz(x, zp, DP, Jz=Jz, \n",
    "                          Kz=Kz, grad_Jz=grad_Jz,\n",
    "                         grad_Kz=grad_Kz)\n",
    "print 'fz(x)', fz\n",
    "print 'gz(x)', gz\n",
    "print 'Fz(x)', Fz\n",
    "print 'Gz(x)', Gz\n",
    "print 'grad_Jz(x)', grad_Jz\n",
    "print 'grad_Kz(x)', grad_Kz\n",
    "print 'grad_gz(x)', grad_gz\n",
    "print 'grad_fz(x)', compute_grad_fz(x, zp, DP)\n",
    "print 'grad_Gz(x)', compute_grad_Gz(x, zp, DP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular matrix E in LSQ subproblem    (Exit mode 5)\n",
      "            Current function value: -305175781.0\n",
      "            Iterations: 61\n",
      "            Function evaluations: 897\n",
      "            Gradient evaluations: 61\n",
      "[  2.50000000e-01   2.50000000e-01   2.50000000e-01   2.50000000e-01\n",
      "  -3.05175781e+08]\n",
      "Singular matrix E in LSQ subproblem\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "# solve an iteration\n",
    "\n",
    "#setup constraints: function of [z,gamma]\n",
    "x0 = np.hstack([zp, 0]) #g0 = 0\n",
    "fun = lambda x: x[-1] # bottom variable is gamma\n",
    "nonneg_cst = dict(type='ineq', fun=lambda x: x[:-1])\n",
    "eq_cst = dict(type='eq', fun=lambda x: sum(x[:-1]) - 1)\n",
    "main_cst = dict(type='ineq', \n",
    "                fun=lambda x,x0,DP: x[-1] -\n",
    "                (compute_u(x[:-1], DP) - compute_v(x0[:-1], DP) - \n",
    "                np.squeeze(np.array((x[:-1] - x0[:-1]) * compute_grad_v(x0[:-1], DP)))), \n",
    "                 args=(x0, DP))\n",
    "cons = (eq_cst, nonneg_cst, main_cst)\n",
    "\n",
    "opt = dict(maxiter=1e8, disp=True)\n",
    "\n",
    "res = minimize(fun, x0, method='SLSQP', constraints=cons, options=opt)\n",
    "print res.x\n",
    "print res.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.63718400e+08   5.57560615e+08   5.54037525e+08]\n",
      "[  6.81409499e+08   5.66113612e+08   5.58242509e+08]\n",
      "[[ -5.48540082e+08  -6.91305066e+07  -5.41857859e+07]\n",
      " [ -1.76239738e+08  -7.43943674e+07  -5.07638570e+07]\n",
      " [ -1.69021612e+08  -5.84902551e+07  -4.98386831e+07]]\n",
      "[ 0.03285454  0.29546081 -0.32831535]\n",
      "[[-883045.53666547 -468191.34872933 -183755.32991866]]\n"
     ]
    }
   ],
   "source": [
    "x = res.x\n",
    "u = compute_u(x, DP) \n",
    "v0 = compute_v(x0[:-1],DP)\n",
    "gv0 = compute_grad_v(x0[:-1], DP)\n",
    "print u\n",
    "print v0\n",
    "print gv0\n",
    "print (x-x0)[:-1]\n",
    "print x[-1] - (u-v0 - (x-x0)[:-1] * gv0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sq_loss(pred,y):\n",
    "    return (pred-y)**2\n",
    "    \n",
    "def compute_loss_k(k, DP):\n",
    "    Dk = DP.get_marginal_density()[:,k]\n",
    "    hk = DP.get_regressor()[:,k]\n",
    "    y = DP.get_true_values()\n",
    "    loss = 0\n",
    "    for x in range(DP.n):\n",
    "        loss += Dk[x] * sq_loss(hk[x], y[x])\n",
    "    return loss / DP.n\n",
    "    \n",
    "def compute_weighted_loss_k(z,k,DP):\n",
    "    Dk = DP.get_marginal_density()[:,k]\n",
    "    \n",
    "    y = DP.get_true_values()\n",
    "    loss = 0\n",
    "    for x in range(DP.n):\n",
    "        hz = compute_hz(x,z,DP)\n",
    "        loss += Dk[x] * sq_loss(hz, y[x])\n",
    "    return loss / DP.n\n",
    "    \n",
    "def compute_weighted_loss(z, DP):\n",
    "    y = DP.get_true_values()\n",
    "    loss = 0\n",
    "    for x in range(DP.n):\n",
    "        Dz = compute_Dz(x,z,DP)\n",
    "        hz = compute_hz(x,z,DP)\n",
    "        loss += Dz * sq_loss(hz, y[x])\n",
    "    return loss / DP.n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L(Dk,hk): 0.0426743639558 0.0343673164216 0.0332143615071\n",
      "L(Dk,hz): 0.0425837364458 0.031093060481 0.0302574192427\n",
      "L(Dz,hz): 0.0352966134819 2.43585795775e-73\n"
     ]
    }
   ],
   "source": [
    "z = res.x[:-1]\n",
    "print 'L(Dk,hk):', compute_loss_k(0,DP), compute_loss_k(1,DP), compute_loss_k(2,DP)\n",
    "print 'L(Dk,hz):', compute_weighted_loss_k(z,0,DP), compute_weighted_loss_k(z,1,DP), compute_weighted_loss_k(z,2,DP)\n",
    "print 'L(Dz,hz):', compute_weighted_loss(z,DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 3)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = DP.get_marginal_density()\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 3)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = DP.get_regressor()\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.58212,  1.90002,  1.17901]), 10694.4)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056043864289248964"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_weighted_loss(z,DP)/(D.max()*DP.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DP.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
